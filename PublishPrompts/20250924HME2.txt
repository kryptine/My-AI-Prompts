Can you explain how homomorphic encryption works, give me initial formalizations of the major fully homomorphic encryption algorithms in Agda, Coq and Lean4 by defining number fields and other concepts as shown in the textbook of Fully Homomorphic Encryption at https://fhetextbook.github.io/ and https://arxiv.org/abs/2503.05136 and can you draft a formalization for the proof that every fully homomorphic encryption scheme mentioned in this book can be made information-theoretically secure by making the key size equal to or larger than the input size, with a textbox that I can copy into other chats for further formalizations of the gaps, which should be marked with `admit` and `sorry`, and can you tell me how to adapt the algorithms in https://arxiv.org/html/2507.07341v1 to allow the user to shield themselves from misaligned AI systems and https://arxiv.org/html/2508.20411v1 to fully secure AI systems, unifying their theory with information-theoretically secure homomorphic encryption schemes by universal one-way functions and universal one-way hash functions according to Levin's construction, as well as formalize Blum's speed-up theorem and their applicability to these problems? Of course these are my compelling hypotheses, the point is that I believe that while using a small key size makes FHE computationally secure, I think that since key sizes can be arbitrarily large, using keys as large as the input or the output might make the system information-theoretically secure like Shamir's secret sharing scheme. For non-standard facts, you should attempt to find ideas to prove them, and just give me initial formalizations as I said. Can you please also attempt to show isomorphisms between the papers 2507.07341 and 2508.20411 by using universal methods to convert generic one-way functions to signature schemes and backwards, showing that AI alignment is just making it follow the user's desires, and this is philosophically, if not mathematically justified by folk theorems (recursive cooperation based on knowledge), open-source game theory based on Lob's theorem for computationally limited systems, Aumann's agreement theorem, the Myerson-Satterthwaite impossibility theorem (a special case of the envelope theorem in economics) showing that in any case, if information is not shared efficiency cannot be achieved regardless of whether the situation is fully cooperative (Aumann) or mixed-motive (Myerson-Satterthwaite envelope)?