Write Part 16 of the pro-accelerationist position paper on AI development based on the precise formal forms and proofs of the following resources by arguing that these methods allows you to act optimally with limited computational or modeling power, by making the arguments based on the formal proofs, theorems and lemmas instead of the general understanding of the concept, making the position paper's argument align with the proofs step-by-step in a way that does not need to necessarily reproduce every step but must still show isomorphisms, by your own ideas and the method of arguing that paper 1 can be implemented with an adaptation of the method from player 4, written for multi-follower Stackelberg games, to multi-leader games, as well as showing that paper 2's generalization of Aumann's agreement theorem works for logically bounded agents who cannot use Bayesian reasoning due to prior-free status using Garrabrant's logical induction and infra-Bayesianism as separate methods, and by fully expanding the omitted steps in the derivation of paper 3 in Coq, Agda and Lean4 formalizations:
1. Emergent Alignment via Competition https://arxiv.org/html/2509.15090v1
2. Collaborative Prediction: Tractable Information Aggregation via Agreement https://arxiv.org/abs/2504.06075
3. Murphys Laws of AI Alignment: Why the Gap Always Wins https://arxiv.org/html/2509.05381v3
4. Finding a Multiple Follower Stackelberg Equilibrium: A Fully First-Order Method https://arxiv.org/html/2509.08161v1
In addition, can you please help me formalize these papers in Agda, Rocq (formerly Coq) and Lean4, by explicitly defining the basic concepts of the paper such as differential equations, convex optimization, probability theory, information theory among others, all the major categories used in these papers, using the same directory/module for the definition of the categories, while separating the propositions, theorems and proofs into their own folders for each paper, by giving the first part of the formalization as far as possible within the context limits and the bound for the pro-accelerationist text, with gaps to be filled in later shown as placeholders like `!!`, `sorry` or `admit`, and with something that can be copied into later chats for formalization of each part in a textbox so that I can request formalization of each file in LLMs later?