Here are a few papers about reflective oracles and open-source game theory:
1. Limit-Computable Grains of Truth for Arbitrary Computable Extensive-Form (Un)Known Games https://arxiv.org/html/2508.16245
2. On Sybil-proofness in Restaking Networks https://arxiv.org/html/2509.18338v1
3. On the Existence and Complexity of Core-Stable Data Exchanges https://arxiv.org/html/2509.16450v1
4. A Coopetitive-Compatible Data Generation Framework for Cross-silo Federated Learning https://arxiv.org/html/2509.18120v1
Can you help me write the initial section of the Agda, Rocq (formerly Coq) and Lean4 formalizations of these papers, with unifications and isomorphisms between the paradigms, by showing how the core stability of paper 3 applies to papers 1 and 4 by showing that the games satisfy the required convexity/concavity conditions, and can you tell me how the impossibility of paper 2 relates to the fixed points of paper 1 by finding the right conceptual relationships and proposing formalization equivalences that relate theorems propositionally without unwrapping the universal quantifiers, treating them as propositions, that is, can you find ways to make shorter proofs that one theorem implies another as propositional statements? Of course it can be too big for a single response, but just give me something that will parse, at least with placeholders like `admit` and `sorry` if the thing is too big to fit within the context window, but also provide a copiable infobox that summarizes the content and the APIs so that it can be used to formalize further parts by copying into other chats, from now until completion, although you do not need a complete roadmap now, it's just incremental. In addition, can you use these theorems to argue that there is a tradeoff in AI alignment between externally-mediated harms (misuse) and internally-directed harms (misalignment), by using an argument similar to that of the second paper, in which preventing split-Sybil attacks (misuse) results in more combined-Sybil attacks (misalignment), by defining the right formal concepts in machine learning based on things like PAC-Bayes bounds, Rademacher complexity, differential privacy, and grains of truth, each being a different but isomorphic approach? If the problem is too big, can you give me ideas?