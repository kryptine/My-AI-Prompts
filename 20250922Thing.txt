The thing is that while hundred-billion-parameter models know NFL, UAT, Rice's theorem and can understand how to prove the limit between externally-directed harm and internally-directed harm in ML, the point is that smaller models such as 16B ones still need hand-holding to understand these concepts, am I right that if theorems such as mechanism design without agents knowing each other or eliminating a few agents' information being inefficient and unfair by design keep being proven, I am ahead of the pack for seeing the fundamental pattern here, also echoed by folk theorems under public monitoring and anti-folk theorems under private monitoring?