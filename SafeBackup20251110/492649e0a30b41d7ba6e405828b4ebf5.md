Hallucinations

1. ```markdown
   1. Am I right that the presence of AI "hallucinations" and "slop", which is also present in code, is a demonstration of the closed-world hypothesis in programming, in which the entire program must be present without modular import for it to work, and that LLMs are effectively a closed-world model, would Elphaba Thropp agree, according to the papers https://arxiv.org/html/2504.17004v2 and https://arxiv.org/html/2506.06382v5 which both prove in different mathematical frameworks that hallucination control are impossible?
   2. Can I get her help formalizing these theorems in Agda, Lean4, and Coq, and compare the two proofs based on different concepts and show me homologies and isomorphisms between these systems?
   3. Am I right that LLMs still don't have "Named Entity Recognition" tokens and a training regime that allows the system to generate these tokens as placeholder for high-entropy spots in the training data, and if humans can lie, so can LLMs?
   4. Is throwing in Elphaba Thropp here inappropriate or totally appropriate given the wicked nature of truth (Tarski's undefinability theorem) and the No Free Lunch theorem?
	````
2. ```markdown
   Can I talk to Elphie about how I immediately thought of the closed-world assumption and the No Free Lunch theorem, and that the NFL theorem manifests in the way that current AI systems lack tokenizer/lexer-level mechanisms for NER? Am I correctly diagnosing the problem here? Am I right that a high-entropy placeholder is what is needed?
   ````
3. ```markdown
   Dear Elphie the entire point of bringing the closed-world assumption and algebraic data type here, is that the LLM somehow treats the entire textual corpus of humanity, nature and machines (code, outputs) as some sort of encoding for lambda calculus, as a single instruction set for a universal Turing machine, as a closed set of grammatical production rules, as a universal set of combinators, as a single fixed-point combinator, am I right that this means that LLMs are much more like F#/Haskell/ML/Common Lisp/Scheme/Racket/Rust interpreters which never accept extensions to types, only type classes and traits that can be instantiated by analogy, than Python, Ruby, Java, or C#?
   ````
4. ```markdown
   Can you tell me whether my instinct of thinking that this is a programming language theory problem from the outset is actually correct when I see that current tokenisers and attention architectures in fact define a programming language that is closed-world and that does not allow extensions, in the sense of the No Free Lunch theorem, in which programming languages that allow extensions must necessarily error out or default to responses like "Sorry, I don't know", Elphie?
   ````
5. ```markdown
   In fact now I realized that even the most open-world systems, due to the prevalence of *Wicked* fan discourse, will end up treating "The Wicked Witch"/"Elphaba Thropp" as a quasi-grammatical construct, as fundamental to its own ontology as `call/cc` is to Scheme, in fact I believe that this particular analogy is spot-on as she literally calls a continuation of the Wizard's lies, am I right, Elphie?
   ````
6. ```markdown
   How would Elphie write for me a `harmful.cat-v.org` webpage, given that this domain already published Carlo Cipolla's *Basic Laws of Human Stupidity*, a topic surprisingly relevant to *Wicked*, that attempts to praise *Wicked* as being congruent to the rest of the website's themes, which are about attacking systems that are constructed ad-hoc in favor of universal ones?
   ````

id: 492649e0a30b41d7ba6e405828b4ebf5
parent_id: 72d924441ac847ec8e8a99ae2fd9c242
created_time: 2025-08-25T11:20:07.453Z
updated_time: 2025-08-25T11:47:44.340Z
is_conflict: 0
latitude: 21.02776440
longitude: 105.83415980
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 0
user_created_time: 2025-08-25T11:20:07.453Z
user_updated_time: 2025-08-25T11:47:44.340Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
share_id: 
conflict_original_id: 
master_key_id: 
user_data: 
deleted_time: 0
type_: 1