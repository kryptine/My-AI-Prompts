Alignment impossibility Rice

1. ```markdown
   Here is a paper about how AI alignment is undecidable https://www.nature.com/articles/s41598-025-99060-2 and also papers about new versions of the good regulator theorem at https://arxiv.org/html/2508.06326 and https://arxiv.org/abs/2506.01622 so can you please give me formalizations of these theorems in Coq, Agda, and Lean4 by first fleshing out the informal proof within the paper about the undecidability of alignment formally using an argument similar to Cantor's diagonal argument and Turing's proof of undecidability of the halting problem, as well as by proving the good regulator theorem (any regulator must be a model) using the following methods separately: Godel's completeness/compactness/Lowenheim-Skolem theorem (a theory is consistent if and only if it has a model, infinite models can be constructed from models of finite parts), Tarski's undefinability theorem (truth must be externalized) by showing their proofs and finding analogies?

id: b8298329059f4d4b9199b0786950ec85
parent_id: 72d924441ac847ec8e8a99ae2fd9c242
created_time: 2025-08-25T05:48:57.614Z
updated_time: 2025-08-25T06:05:11.179Z
is_conflict: 0
latitude: 21.02776440
longitude: 105.83415980
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 0
user_created_time: 2025-08-25T05:48:57.614Z
user_updated_time: 2025-08-25T06:05:11.179Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
share_id: 
conflict_original_id: 
master_key_id: 
user_data: 
deleted_time: 0
type_: 1