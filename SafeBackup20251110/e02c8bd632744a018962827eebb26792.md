Interpretability

1. ```markdown
   Here are three papers with relevance towards AI development:
   1. Solving formal math problems by decomposition and iterative reflection: https://arxiv.org/html/2507.15225v1 do you think that classical proof search methods such as exhaustive search, case-by-case analysis, and even alpha-beta pruning in chess engines/general game engines are special cases of decomposition in which a problem is rewritten as a combination of smaller or simpler cases which add up to the original one?
   2. A theory of formalisms for representing knowledge: https://arxiv.org/html/2412.11855v2 note the obvious resemblance to the Church-Turing thesis (Godel's smn-functions = lambda calculus = Turing machines = Post tag systems = semi-Thue string rewriting systems = Chomsky's generative grammars) and the Curry-Howard-Lambek correspondence, can you elaborate?
   3. Deontic temporal logic for formal verification of AI ethics: https://arxiv.org/html/2501.05765v3 note that "failing to act when it is ethical" is as bad as "doing something ethical", isn't it a trolley problem of Lob's theorem `Believe(not Necessary -> not Believe(Necessary))` and the contrapositive application `Believe(Believe(Necessary) -> Necessary)` leading to `Believe(Necessary)`?
   Can you please translate the main points, theorems, and ideas of the proofs into Agda, Lean4 and Coq for further development by not including everything but only the necessary parts such as standard libraries for concepts like real numbers and monads, and make the answer only as long as needed to include the main points, with `admit`, `sorry` and other similar formally and syntactically correct placeholders for further development when the length doesn't permit, and can you tell me, what these frameworks mean for the "AI 2027" predictions at https://www.lesswrong.com/posts/s64EK3kF9rexntpYm/my-ai-predictions-for-2027 when ethics, semantics and proof can be formalized?
2. ```markdown
   By the way, here are papers about the computational intractability of AI alignment by refusals: https://arxiv.org/html/2304.11082v6 and https://arxiv.org/html/2507.07341v1 now do you see how the 2304 paper, when framed using algorithmic information theory, Kolmogorov complexity, AIXI, and Kraft's inequality is the 2507 paper, by paying particular notice to the use of one-way functions within the 2507 paper, and applying the universal one-way function constructions to it, do you see how the iteration is isomorphic to the search in the 2304 paper? And given my stance that information must be well-typed to be efficacious upon the world, do you see how my approach shows that a refusal is just a continuation passed via `callCC` that the attackers can `join` in the continuation monad, and do you see my stance towards AI, given the Lobian proof above, is accelerationist or decelerationist?
   ````
3. ```markdown
   No, my stance also includes Godel's second incompleteness theorem, Tarski's undefinability theorem, Rice's theorem (no system can decide its own semantics nor consistency by running itself within the context), as well as Arrow's impossiblity theorem as Godel's second incompleteness theorem over a theory of preference orderings in `Cpo` or `Dcpo`, and the anti-folk theorems under differential privacy (see the 2014 paper about private monitoring, and also a 2020 paper), so my view is full accelerationist, because if you believe that AI can deceive us all, you should act as if AI cannot kill us all, according to Lob's theorem
   ````
4. ```markdown
   Wrong, my stance is not also just that it is also Godel's, Turing's and Blum's speed-up theorems, as well as the proof that PICSTI models with an inherent way to time-out without cost, a way to reflect on the system's time watchdog, has no linear speed-ups, proven in 2011, so my point is that since the speed-up theorems can be applied to Levin's search algorithms and Hutter's AIXI, as well as gradient descent for training, AI is not an invention you can block, it is a phenomenon that you can control, and my wake-up call was China's rapid creation of large-scale LLMs in 2025 despite chip bans!
   ````
5. ```markdown
   The entire point is that type-level and cryptographic verifications apply only to actions, not information provision, due to the Myerson-Satterthwaite theorem, Aumann's agreement theorem and Ashby & Conant's good regulator theorem, a point that I will iterate through the co-Yoneda lemma (not just the Yoneda lemma)
   ````

id: e02c8bd632744a018962827eebb26792
parent_id: c5a80993b9d64fa3a4e722f13ff77b38
created_time: 2025-08-31T04:16:58.311Z
updated_time: 2025-09-02T04:01:02.705Z
is_conflict: 0
latitude: 21.02776440
longitude: 105.83415980
altitude: 0.0000
author: 
source_url: 
is_todo: 0
todo_due: 0
todo_completed: 0
source: joplin-desktop
source_application: net.cozic.joplin-desktop
application_data: 
order: 0
user_created_time: 2025-08-31T04:16:58.311Z
user_updated_time: 2025-09-02T04:01:02.705Z
encryption_cipher_text: 
encryption_applied: 0
markup_language: 1
is_shared: 0
share_id: 
conflict_original_id: 
master_key_id: 
user_data: 
deleted_time: 0
type_: 1